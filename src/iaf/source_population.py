from typing import Literal, Optional
from abc import ABC, abstractmethod
import numpy as np
from ..utils import create_rng


class SourcePopulation(ABC):
    @abstractmethod
    def generate_rates(self, dt: float, tau_stim: float = 0.01) -> tuple[np.ndarray, int]:
        """
        Generate input rates and an interval for how long to keep them.
        """
        pass


class SourcePopulationICA(SourcePopulation):
    """
    A population of input sources with shared properties.

    This class generates input rates for a population of neurons based on different
    source loading methods. The input rates are generated as a combination of
    independent signals and noise.

    Attributes
    ----------
    num_inputs : int
        The number of input neurons.
    num_signals : int
        The number of independent components/signals.
    source_method : str
        The method for generating source loading ('divide' or 'gauss').
    source_strength : float
        The signal-to-noise ratio.
    rate_std : float
        The standard deviation of the input rates.
    rate_mean : float
        The mean of the input rates.
    source_loading : np.ndarray
        The loading matrix of shape (num_signals, num_inputs).
    var_adjustment : np.ndarray
        The variance adjustment factor for each input.
    """

    def __init__(
        self,
        num_inputs: int = 100,
        num_signals: int = 3,
        source_method: Literal["divide", "gauss", "correlated"] = "gauss",
        source_strength: float = 3.0,
        rate_std: float = 10.0,
        rate_mean: float = 20.0,
        gauss_source_width: float = 2 / 5,
        seed: Optional[int] = None,
    ):
        """
        Initialize the source population.

        Parameters
        ----------
        num_inputs : int
            The number of input neurons.
        num_signals : int
            The number of independent components/signals.
        source_method : str
            The method for generating source loading ('divide' or 'gauss').
        source_strength : float
            The signal-to-noise ratio.
        rate_std : float
            The standard deviation of the input rates.
        rate_mean : float
            The mean of the input rates.
        gauss_source_width : float
            The width of the Gaussian source.
        seed : int, optional
            Random seed for reproducibility.
        """
        self.num_inputs = num_inputs
        self.num_signals = num_signals
        self.source_method = source_method
        self.source_strength = source_strength
        self.rate_std = rate_std
        self.rate_mean = rate_mean
        self.gauss_source_width = gauss_source_width

        # Initialize random number generator
        self.rng = create_rng(seed)

        # Create source loading based on method
        self.source_loading = self._create_source_loading()

        # Calculate variance adjustment
        self.var_adjustment = np.sqrt(np.sum(self.source_loading**2, axis=0) + 1)

    @classmethod
    def estimate_correlation(cls, source_loading: np.ndarray) -> np.ndarray:
        """Estimate the correlation of each neuron with each latent signal.

        The input rates are generated by combining the latent signal with noise,
        proportional to the source loading for each input neuron. If there was only
        one signal, the total variance of the neuron is a sum of the squared loadings
        plus 1 (for the noise). Therefore, the correlation of neuron 0 with signal i
        is equal to:

        .. math::

            corr(x_0, s_i) = \\sqrt{\\frac{w_{0,i}^2}{\\sum_{j} w_{0,j}^2 + 1}}

        where :math:`w_{0,i}` is the source loading of neuron 0 for signal i.

        In practice, this isn't the true correlation because we have limited samples
        and the input rates are clipped to be nonnegative.
        """
        estimate = np.zeros_like(source_loading)
        for isource, loading in enumerate(source_loading):
            estimate[isource] = np.sqrt(loading**2 / (np.sum(source_loading**2, axis=0) + 1))
        return estimate

    def _create_source_loading(self) -> np.ndarray:
        """
        Create the source loading matrix based on the specified method.

        Returns
        -------
        np.ndarray
            The source loading matrix of shape (num_signals, num_inputs).
        """
        if self.source_method == "divide":
            return self._create_divide_loading()
        elif self.source_method == "gauss":
            return self._create_gauss_loading()
        else:
            raise ValueError(f"Invalid source method: {self.source_method}")

    def _create_divide_loading(self) -> np.ndarray:
        """
        Create source loading using the 'divide' method.

        This method divides the inputs evenly among the signals.

        Returns
        -------
        np.ndarray
            The source loading matrix of shape (num_signals, num_inputs).
        """
        num_input_per_signal = self.num_inputs // self.num_signals
        source_loading = np.zeros((self.num_signals, self.num_inputs))

        for signal in range(self.num_signals):
            start_idx = signal * num_input_per_signal
            end_idx = (signal + 1) * num_input_per_signal
            source_loading[signal, start_idx:end_idx] = self.source_strength

        return source_loading

    def _create_gauss_loading(self) -> np.ndarray:
        """
        Create source loading using the 'gauss' method.

        This method creates Gaussian-shaped loadings for each signal,
        with peaks evenly spaced across the input space.

        Returns
        -------
        np.ndarray
            The source loading matrix of shape (num_signals, num_inputs).
        """
        shift_input_per_signal = self.num_inputs // self.num_signals
        width_gauss = self.gauss_source_width * shift_input_per_signal

        # Create a Gaussian centered at the middle of the input space
        idx_gauss = np.arange(self.num_inputs) - self.num_inputs // 2
        gauss_loading = np.exp(-(idx_gauss**2) / (2 * width_gauss**2))

        # Shift the Gaussian to the first signal position
        first_input_signal_idx = shift_input_per_signal // 2
        idx_peak_gauss = np.argmax(gauss_loading)
        gauss_loading = np.roll(gauss_loading, first_input_signal_idx - idx_peak_gauss)

        # Create shifted versions for each signal
        shifts = np.arange(self.num_signals) * shift_input_per_signal
        source_loading = np.vstack([np.roll(gauss_loading, shift) for shift in shifts])

        # Scale by source strength
        source_loading *= self.source_strength

        return source_loading

    def _generate_new_rates(self) -> np.ndarray:
        """
        Generate new input rates.

        Returns
        -------
        np.ndarray
            The input rates for each input neuron in the source population.
        """
        # Generate random signal components
        signal_components = self.rng.standard_normal(self.num_signals)

        # Generate random noise components
        noise_components = self.rng.standard_normal(self.num_inputs)

        # Combine signal and noise
        input_vec = (noise_components + signal_components.dot(self.source_loading)) / self.var_adjustment

        # Scale and shift to get rates
        rate = self.rate_std * input_vec + self.rate_mean

        # No negative rates
        rate = np.maximum(rate, 0)

        return rate

    def generate_rates(self, dt: float, tau_stim: float = 0.01) -> tuple[np.ndarray, int]:
        """
        Generate input rates and an interval for how long to keep them.

        Parameters
        ----------
        dt : float
            The time step in seconds.
        tau_stim : float
            Time constant for stimulus in seconds.

        Returns
        -------
        tuple[np.ndarray, int]
            The input rates and the number of time steps to keep them.
        """
        # Convert time constant to number of samples
        tau_stim_samples = round(tau_stim / dt)

        # Generate exponential interval (minimum 1)
        interval = int(self.rng.exponential(tau_stim_samples)) + 1

        # Generate rates
        rates = self._generate_new_rates()

        return rates, interval
